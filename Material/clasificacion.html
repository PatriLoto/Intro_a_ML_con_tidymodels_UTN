<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>clasificacion.utf8</title>
    <meta charset="utf-8" />
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/xaringanExtra_fit-screen/fit-screen.js"></script>
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


background-image: url(img/juti2.png)
background-size: cover
class: animated slideInRight fadeOutLeft, middle




















# Introducci√≥n a Machine learning con `tidymodels`


### JUTI 2020

---

## Equipo


        
&lt;img src="img/patri-rox.png" width="100%" style="display: block; margin: auto;" /&gt;



---



## Aprendizaje Autom√°tico ü§ñ

.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
### El aprendizaje autom√°tico (ML)-tambi√©n llamado aprendizaje estad√≠stico- es un subcampo dentro de la inteligencia artificial (IA) donde *los algoritmos "aprenden" patrones en los datos para realizar una tarea espec√≠fica.* 

]

---

## Conceptos Importantes üí°

* __Muestra, punto, observaci√≥n, instancia__ se refiere a una unidad de an√°lisis.
&lt;br&gt;

* __Set de entrenamiento__ son los datos utilizados para el modelado. 
&lt;br&gt;

* __Set de prueba__ son los datos utilizados para medir el desempe√±o del modelo, entre un conjunto de candidatos. 
&lt;br&gt;

* __Atributos, predictores, variables independientes o descriptores__ son los datos de entrada para la ecuaci√≥n de predicci√≥n.
&lt;br&gt; 
* __Salida, variable dependiente, variable respuesta, clase, o "target"__ es la cantidad a ser predicha. 
&lt;br&gt;



.footnote[&lt;sup&gt;*&lt;/sup&gt; Applied Predictive Modeling]





---

## Tipos de aprendizaje
        
&lt;img src="img/ml.png" width="90%" style="display: block; margin: auto;" /&gt;




---

## Aprendizaje supervisado

&lt;img src="img/supervised.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[&lt;sup&gt;*&lt;/sup&gt; Machine Learning with R, the tidyverse and mlr]


---

## Algunos hitos del campo de IA  üß†

        
&lt;img src="img/AI-hits.png" width="100%" style="display: block; margin: auto;" /&gt;






---

## Entrenamiento, validaci√≥n y testeo



&lt;img src="img/train-val-test.jpeg" width="40%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: https://www.tmwr.org/resampling.html]





---

# √Årboles de decisi√≥n

  
&lt;img src="img/bret-tree.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Imagen tomada de https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-r-second-edition]

---

## Hiperpar√°metro



.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
### Un hiperpar√°metro es una propiedad de un algoritmo de aprendizaje. Este valor influencia la forma en que trabaja el algoritmo. Estos valores no son aprendidos por el algoritmo desde los datos. Deben ser seteados antes de correr el algoritmo por el analista. 
]


.footnote[The Hundred-page machine learning book. Andriy Burkov]


---

## Hiperpar√°metros de 
## √°rboles de decisi√≥n

.panelset[
.panel[.panel-name[min_n]

Establezca n m√≠nimo para dividir en cualquier nodo.

Es un m√©todo de parada temprana. Se utiliza para evitar el sobreajuste.

]



.panel[.panel-name[tree_depth]

Pone un l√≠mite a la profundidad m√°xima del √°rbol.

Un m√©todo para detener el algoritmo. Se utiliza para evitar el sobreajuste.

]

.panel[.panel-name[cost_complexity]

Agrega un costo o penalizaci√≥n a los errores de √°rboles m√°s complejos. 

Es una forma de poda. Utilizado para evitar el sobreajuste (overfitting).


]


]

---

## Matriz de Confusi√≥n
      
  
&lt;img src="img/matriz-confusion.png" width="100%" style="display: block; margin: auto;" /&gt;

    


.footnote[Traducido de 10.7717/peerj.5666/fig-2]




---
## De caret a `tidymodels`



.pull-left[
El objetivo de caret era **unificar la sintaxis** para modelizar datos usando como base distintas librer√≠as de R. 
&lt;img src="img/caret.png" width="100%" align="right" /&gt;
]

--

.pull-right[
El objetivo de Tidymodels es adem√°s hacerlo **en un formato ordenado**. 
&lt;img src="img/tidymodels.png" width="80%" align="right" /&gt;

]


---
## `tidymodels`

.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[

### `tidymodels` es un grupo de paquetes centrado en las tareas de modelizaci√≥n de datos. 
### La modelizaci√≥n consta de varios pasos, la idea es que cada paso lo realice una librer√≠a diferente. 
]



.footnote[Sitio web: https://www.tidymodels.org/]

---

# Etapas del modelado de datos


  
&lt;img src="img/modeling.png" width="100%" style="display: block; margin: auto;" /&gt;

.footnote[Sitio web: https://www.tmwr.org/software-modeling.html]


---

## Modelado y `tidymodels`


&lt;img src="img/tidy-w.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## Librer√≠as de `tidymodels`


.left-column[
### `library(rsample)`
__Librer√≠a que nos permite hacer divisi√≥n del set de datos__

]

.right-column[

&lt;img src="img/rsample.png" width="40%" style="display: block; margin: auto;" /&gt;

]





---

## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
### `library(recipes)`
__Permite hacer preprocesamiento de los datos__
]

.right-column[

&lt;img src="img/recipes.png" width="40%" style="display: block; margin: auto;" /&gt;


]

---
## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
### `library(parsnip)`
__Permite unificar los modelos a optimizar__
]

.right-column[

&lt;img src="img/parsnip.png" width="40%" style="display: block; margin: auto;" /&gt;


]


---
## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
#### `library(parsnip)`
### `library(workflows)`
__Nos permite unificar el flujo de trabajo__

]

.right-column[

&lt;img src="img/workflow.png" width="40%" style="display: block; margin: auto;" /&gt;


]


---
## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
#### `library(parsnip)`
#### `library(workflows)`
### `library(tune)`
__Permite el tuneo de los hiperpar√°metros de los modelos__
]

.right-column[

&lt;img src="img/tune.png" width="40%" style="display: block; margin: auto;" /&gt;


]



---

## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
#### `library(parsnip)`
#### `library(workflows)`
#### `library(tune)`
### `library(yardstick)`
__Permite evaluar las m√©tricas de los modelos__
]

.right-column[

&lt;img src="img/yardstick.png" width="40%" style="display: block; margin: auto;" /&gt;


]



---

## Vamos a modelar las especies üêß

### Ingreso los datos 

```r
library(tidymodels) 
library(palmerpenguins)

penguins &lt;- palmerpenguins::penguins %&gt;%
  drop_na() %&gt;% #elimino valores perdidos
  select(-year,-sex, -island) #elimino columnas q no son num√©ricas
glimpse(penguins) #observo variables restantes
```

```
## Rows: 333
## Columns: 5
## $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ade‚Ä¶
## $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.‚Ä¶
## $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.‚Ä¶
## $ flipper_length_mm &lt;int&gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 1‚Ä¶
## $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 380‚Ä¶
```



---

### Paso 1: Vamos a dividir el set de datos 


```r
library(rsample)
set.seed(123) #setear la semilla
p_split &lt;- penguins %&gt;%
  initial_split(prop=0.75) # divido en 75%

p_train &lt;- training(p_split)

p_split
```

```
## &lt;Analysis/Assess/Total&gt;
## &lt;250/83/333&gt;
```

```r
# para hacer validaci√≥n cruzada estratificada
p_folds &lt;- vfold_cv(p_train, strata = species) 
```


Estos son los datos de entrenamiento/prueba/total 

* __Vamos a _entrenar_ con 250 muestras__
* __Vamos a _testear_ con 83 muestras__
* __Datos totales: 333__


---

### Paso 2: Preprocesamiento (receta) 


```r
#creo la receta
recipe_dt &lt;- p_train %&gt;%
  recipe(species~.) %&gt;%
  step_corr(all_predictors()) %&gt;% #elimino las correlaciones
  step_center(all_predictors(), -all_outcomes()) %&gt;% #centrado
  step_scale(all_predictors(), -all_outcomes()) %&gt;% #escalado
  prep() 
recipe_dt #ver la receta
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          4
## 
## Training data contained 250 data points and no missing data.
## 
## Operations:
## 
## Correlation filter removed no terms [trained]
## Centering for bill_length_mm, ... [trained]
## Scaling for bill_length_mm, ... [trained]
```




---
background-image: url(img/dt-fondo.png)
background-size: cover

### Paso 3: Especificar el modelo  üå≥

__Modelo de √°rboles de decisi√≥n__

__Vamos a utilizar el modelo por defecto__


```r
#especifico el modelo 
set.seed(123)
vanilla_tree_spec &lt;- decision_tree() %&gt;% #arboles de decisi√≥n
  set_engine("rpart") %&gt;% #librer√≠a rpart
  set_mode("classification") #modo para clasificar
vanilla_tree_spec
```

```
## Decision Tree Model Specification (classification)
## 
## Computational engine: rpart
```



---
background-image: url(img/dt-fondo.png)
background-size: cover

### Paso 4: armo el workflow 


```r
#armo el workflow
tree_wf &lt;- workflow() %&gt;%
  add_recipe(recipe_dt) %&gt;% #agrego la receta
  add_model(vanilla_tree_spec) #agrego el modelo
tree_wf 
```

```
## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: decision_tree()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 3 Recipe Steps
## 
## ‚óè step_corr()
## ‚óè step_center()
## ‚óè step_scale()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Decision Tree Model Specification (classification)
## 
## Computational engine: rpart
```


---

background-image: url(img/dt-fondo.png)
background-size: cover

### Paso 5: Ajuste de la funci√≥n


```r
#modelo vanilla sin tunning
set.seed(123) 
vanilla_tree_spec %&gt;% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %&gt;% 
  collect_metrics() #desanidar las metricas
```

```
## # A tibble: 2 x 5
##   .metric  .estimator  mean     n std_err
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 accuracy multiclass 0.951    10 0.0123 
## 2 roc_auc  hand_till  0.970    10 0.00794
```




---

background-image: url(img/dt-fondo.png)
background-size: cover

#### Paso 5.1: vamos a especificar 2 hiperpar√°matros 


```r
set.seed(123) 
trees_spec &lt;- decision_tree() %&gt;% 
  set_engine("rpart") %&gt;% 
  set_mode("classification") %&gt;% 
  set_args(min_n = 20, cost_complexity = 0.1) #especifico hiperpar√°metros

trees_spec %&gt;%
  fit_resamples(species ~ ., 
                resamples = p_folds) %&gt;% 
  collect_metrics()
```

```
## # A tibble: 2 x 5
##   .metric  .estimator  mean     n std_err
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 accuracy multiclass 0.951    10 0.0123 
## 2 roc_auc  hand_till  0.970    10 0.00794
```


---

background-image: url(img/dt-fondo.png)
background-size: cover



# Ejercicio


.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
#### 1. ¬øPor qu√© es el mismo valor obtenido en los dos casos?

#### 2. Dejando fijo el valor de min_n=20, pruebe C=1, C=0.5 y C=0.
#### 3. Dejando fijo el valor de C=0, pruebe min_n 1 y 5.
]


<div class="countdown" id="timer_5f74a8dc" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

    

---
background-image: url(img/dt-fondo.png)
background-size: cover

### Paso 6: Predicci√≥n del modelo  üîÆ




```r
#utilizamos la funcion last_fit junto al workflow y al split de datos
final_fit_dt &lt;- last_fit(tree_wf,
  split = p_split
)
final_fit_dt %&gt;%
  collect_metrics()
```

```
## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy multiclass     0.880
## 2 roc_auc  hand_till      0.924
```


---

background-image: url(img/dt-fondo.png)
background-size: cover

### Paso 6.1: matriz de confusi√≥n 

  

```r
final_fit_dt %&gt;%
  collect_predictions() %&gt;%
  conf_mat(species, .pred_class) #para ver la matriz de confusi√≥n
```

```
##            Truth
## Prediction  Adelie Chinstrap Gentoo
##   Adelie        35         0      0
##   Chinstrap      5         9      2
##   Gentoo         1         2     29
```

--



```r
final_fit_dt %&gt;%
  collect_predictions() %&gt;%
  sens(species, .pred_class) #sensibilidad global del modelo
```

```
## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 sens    macro          0.869
```


---

background-image: url(img/dt-fondo.png)
background-size: cover

# Ejercicio


.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
#### Repetir estos pasos para el modelo de C=0 y min_n=5
]

<div class="countdown" id="timer_5f74a955" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>






---


background-image: url(img/dt-fondo.png)
background-size: cover

## Resumiendo

.left-column[
### Paso 1:
__Dividimos los datos__


* initial_split()




]

.right-column[

&lt;img src="img/rsample.png" width="40%" style="display: block; margin: auto;" /&gt;

]


---


background-image: url(img/dt-fondo.png)
background-size: cover


## Resumiendo

.left-column[
### Paso 2:
__Preprocesamiento de los datos__

* step_*()

]

.right-column[

&lt;img src="img/recipes.png" width="40%" style="display: block; margin: auto;" /&gt;

]

---


background-image: url(img/dt-fondo.png)
background-size: cover


## Resumiendo

.left-column[
### Paso 3:
__Especificamos el modelo y sus args__

* set_engine()
* mode()

]

.right-column[

&lt;img src="img/parsnip.png" width="40%" style="display: block; margin: auto;" /&gt;

]


---

background-image: url(img/dt-fondo.png)
background-size: cover


## Resumiendo

.left-column[
### Paso 4: 
__Armamos el workflow con la receta y el modelo__

* workflow()
* add_recipe()
* add_model()

]

.right-column[

&lt;img src="img/workflow.png" width="40%" style="display: block; margin: auto;" /&gt;

]

---


background-image: url(img/dt-fondo.png)
background-size: cover

## Resumiendo

.left-column[
### Paso 5: Tune
__Tuneo de los hiperpar√°metros__

* last_fit()
]

.right-column[

&lt;img src="img/tune.png" width="40%" style="display: block; margin: auto;" /&gt;

]




---



background-image: url(img/dt-fondo.png)
background-size: cover

## Resumiendo

.left-column[
### Paso 6:
__Predicci√≥n y comparaci√≥n de las m√©tricas__

* collect_metrics()
* collect_predictions() + conf_mat()

]

.right-column[

&lt;img src="img/yardstick.png" width="40%" style="display: block; margin: auto;" /&gt;

]


---

background-image: url(img/juti2.png)
background-size: cover
class: animated slideInRight fadeOutLeft, middle

    
# Random Forest


---



# Random Forest

 
&lt;img src="img/random-forest1.png" width="90%" style="display: block; margin: auto;" /&gt;


.footnote[Imagen tomada de https://conf20-intro-ml.netlify.com/]

---

# Bootstraping

 
&lt;img src="img/random-forest2.png" width="100%" style="display: block; margin: auto;" /&gt;

.footnote[Imagen tomada de https://conf20-intro-ml.netlify.com/]


---

# Bagging
 
&lt;img src="img/random-forest3.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Imagen tomada de]

---
### Veamos que sucede al clasificar el conjunto de testeo
 
&lt;img src="img/random-forest4.png" width="100%" style="display: block; margin: auto;" /&gt;

.footnote[Imagen tomada de https://conf20-intro-ml.netlify.com/]

---
### Voto mayoritario (majority vote)
 
&lt;img src="img/random-forest5.png" width="100%" style="display: block; margin: auto;" /&gt;

.footnote[Imagen tomada de https://conf20-intro-ml.netlify.com/]


---

### Hiperpar√°metros de 
### random forest

### mtry
* El n√∫mero de predictores a muestrearse en cada split de √°rbol

--

### min_n
* el n√∫mero de observaciones necesarias para seguir dividiendo nodos

  
---

background-image: url(img/rf-fondo.png)
background-size: cover
  
  
### Paso 2: Preprocesamos los datos


```r
p_recipe &lt;- training(p_split) %&gt;%
  recipe(species~.) %&gt;%
  step_corr(all_predictors()) %&gt;%
  step_center(all_predictors(), -all_outcomes()) %&gt;%
  step_scale(all_predictors(), -all_outcomes()) %&gt;%
  prep()
p_recipe
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          4
## 
## Training data contained 250 data points and no missing data.
## 
## Operations:
## 
## Correlation filter removed no terms [trained]
## Centering for bill_length_mm, ... [trained]
## Scaling for bill_length_mm, ... [trained]
```

---

background-image: url(img/rf-fondo.png)
background-size: cover

### Paso 3: Especificar el modelo

```r
rf_spec &lt;- rand_forest() %&gt;% 
  set_engine("ranger") %&gt;% 
  set_mode("classification")
```

---

### Veamos como funciona el modelo sin tunning

```r
set.seed(123)

rf_spec %&gt;% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %&gt;% 
  collect_metrics()
```

```
## # A tibble: 2 x 5
##   .metric  .estimator  mean     n std_err
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 accuracy multiclass 0.972    10 0.0108 
## 2 roc_auc  hand_till  0.996    10 0.00192
```


---
background-image: url(img/rf-fondo.png)
background-size: cover

## Random Forest con mtry=2  üîß


```r
rf2_spec &lt;- rf_spec %&gt;% 
  set_args(mtry = 2)

set.seed(123)

rf2_spec %&gt;% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %&gt;% 
  collect_metrics()
```

```
## # A tibble: 2 x 5
##   .metric  .estimator  mean     n std_err
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 accuracy multiclass 0.972    10 0.0108 
## 2 roc_auc  hand_till  0.996    10 0.00192
```


---
background-image: url(img/rf-fondo.png)
background-size: cover

## Random Forest con mtry=3  üîß


```r
rf3_spec &lt;- rf_spec %&gt;% 
  set_args(mtry = 3)

set.seed(123)

rf3_spec %&gt;% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %&gt;% 
  collect_metrics()
```

```
## # A tibble: 2 x 5
##   .metric  .estimator  mean     n std_err
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 accuracy multiclass 0.967    10 0.0104 
## 2 roc_auc  hand_till  0.997    10 0.00115
```


---

background-image: url(img/rf-fondo.png)
background-size: cover

## Random Forest con mtry=4  üîß


```r
rf4_spec &lt;- rf_spec %&gt;% 
  set_args(mtry = 4)

set.seed(123)
rf4_spec %&gt;% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %&gt;% 
  collect_metrics()
```

```
## # A tibble: 2 x 5
##   .metric  .estimator  mean     n std_err
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 accuracy multiclass 0.964    10 0.00972
## 2 roc_auc  hand_till  0.996    10 0.00147
```


---
background-image: url(img/rf-fondo.png)
background-size: cover


### Tuneo de hiperpar√°metros autom√°tico üîß


```r
tune_spec &lt;- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
) %&gt;%
  set_mode("classification") %&gt;%
  set_engine("ranger")
tune_spec
```

```
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 1000
##   min_n = tune()
## 
## Computational engine: ranger
```

---
background-image: url(img/rf-fondo.png)
background-size: cover


## Workflows


```r
tune_wf &lt;- workflow() %&gt;%
  add_recipe(p_recipe) %&gt;%
  add_model(tune_spec)

set.seed(123)
cv_folds &lt;- vfold_cv(p_train, strata = species)
tune_wf
```

```
## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: rand_forest()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 3 Recipe Steps
## 
## ‚óè step_corr()
## ‚óè step_center()
## ‚óè step_scale()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 1000
##   min_n = tune()
## 
## Computational engine: ranger
```

---

background-image: url(img/rf-fondo.png)
background-size: cover

### Paralelizamos los c√°lculos


```r
doParallel::registerDoParallel()

set.seed(123)
tune_res &lt;- tune_grid(
  tune_wf,
  resamples = cv_folds,
  grid = 20
)

tune_res
```

```
## # Tuning results
## # 10-fold cross-validation using stratification 
## # A tibble: 10 x 4
##    splits           id     .metrics          .notes          
##    &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          
##  1 &lt;split [224/26]&gt; Fold01 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  2 &lt;split [224/26]&gt; Fold02 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  3 &lt;split [224/26]&gt; Fold03 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  4 &lt;split [224/26]&gt; Fold04 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  5 &lt;split [224/26]&gt; Fold05 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  6 &lt;split [225/25]&gt; Fold06 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  7 &lt;split [225/25]&gt; Fold07 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  8 &lt;split [226/24]&gt; Fold08 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
##  9 &lt;split [227/23]&gt; Fold09 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
## 10 &lt;split [227/23]&gt; Fold10 &lt;tibble [40 √ó 6]&gt; &lt;tibble [0 √ó 1]&gt;
```

---

background-image: url(img/rf-fondo.png)
background-size: cover

## Rango de valores para min_n y mtry

![](clasificacion_files/figure-html/unnamed-chunk-47-1.png)&lt;!-- --&gt;


---
background-image: url(img/rf-fondo.png)
background-size: cover

## Elijo el mejor modelo üèÜ

* Con la funci√≥n select_best


```r
best_auc &lt;- select_best(tune_res, "roc_auc")

final_rf &lt;- finalize_model(
  tune_spec,
  best_auc
)

final_rf
```

```
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = 2
##   trees = 1000
##   min_n = 7
## 
## Computational engine: ranger
```


---

background-image: url(img/rf-fondo.png)
background-size: cover

## Valores finales

```r
set.seed(123)
final_wf &lt;- workflow() %&gt;%
  add_recipe(p_recipe) %&gt;%
  add_model(final_rf)

final_res &lt;- final_wf %&gt;%
  last_fit(p_split)

final_res %&gt;%
  collect_metrics()
```

```
## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy multiclass     0.988
## 2 roc_auc  hand_till      1
```



---

background-image: url(img/rf-fondo.png)
background-size: cover

## Ejercicio 3

.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
#### Con el set de datos de iris realice una clasificaci√≥n con random forest. 

]

<div class="countdown" id="timer_5f74a6df" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---


## Resumiendo

.left-column[
### Paso 2: Recipes
__Preprocesamiento de los datos__
]

.right-column[

&lt;img src="img/recipes.png" width="40%" style="display: block; margin: auto;" /&gt;

]

---


## Resumiendo

.left-column[
### Paso 3: Parsnip
__Especificamos el modelo y sus args__
]

.right-column[

&lt;img src="img/parsnip.png" width="40%" style="display: block; margin: auto;" /&gt;

]
---


## Resumiendo

.left-column[
### Paso 4: Workflow
__Armamos el workflow con la receta y el modelo__
]

.right-column[

&lt;img src="img/workflow.png" width="40%" style="display: block; margin: auto;" /&gt;

]

---

## Resumiendo

.left-column[
### Paso 5: Tune
__Tuneo de los hiperpar√°metros__

]

.right-column[

&lt;img src="img/tune.png" width="40%" style="display: block; margin: auto;" /&gt;

]


---

## Resumiendo

.left-column[
### Paso 6:
__Predicci√≥n y comparaci√≥n de las m√©tricas__
]

.right-column[

&lt;img src="img/yardstick.png" width="40%" style="display: block; margin: auto;" /&gt;

]





---

### Ejemplos (un poco) m√°s reales

#### [Tuning random forest hyperparameters with #TidyTuesday trees data](https://juliasilge.com/blog/sf-trees-random-tuning/)

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
#### [Hyperparameter tuning and #TidyTuesday food consumption](https://juliasilge.com/blog/food-hyperparameter-tune/)



---

background-image: url(img/biblio.png)
background-size: cover


# Bibliograf√≠a


#### Max Kuhn &amp; Julia Silge - [Tidy Modeling (en desarrollo)](https://www.tmwr.org/)

#### Julia Silge's [Personal Blog](https://juliasilge.com/blog/)

#### Max Kuhn &amp; Kjell Johnson - [Feature engineering and Selection: A Practical Approach for Predictive Models](http://www.feat.engineering/)

#### Max Kuhn &amp; Kjell Johnson - Applied Predictive Modeling

#### Documentaci√≥n de [`tidymodels`](https://www.tidymodels.org/)

#### Alison Hill [rstudio conf](https://conf20-intro-ml.netlify.app/materials/) y [curso virtual](https://alison.rbind.io/post/2020-06-02-tidymodels-virtually/) material

---

background-image: url(img/juti2.png)
background-size: cover
class: middle

# Muchas gracias ü§ñ
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

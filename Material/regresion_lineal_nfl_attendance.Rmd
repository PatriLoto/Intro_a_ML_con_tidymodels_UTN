---
title: "Regresión con datos de NFL_attendance"
author: "Basado en el blog de Julia Silge"
date: "29/9/2020"
output: 
  html_document:
     theme: "journal"
     dev: png
     highlight: "default"
     toc: true
     toc_float: true
     code_folding: hide
---



```{r librerias-utiles, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
library(hrbrthemes)
theme_set(theme_fivethirtyeight())

```

## Dataset

Utilizaremos los datos de [#Tidytuesday](https://github.com/rfordatascience/tidytuesday), la cual es una iniciativa de la comunidad de R, en la cual se publica semanalmente un set de datos con el objetivo de practicar las habilidades de procesamiento, visualización y modelado de datos. El dataset elegido contiene datos de los juegos de fútbol americano de USA.

## Lectura de datos

```{r nfl_attandance, include=FALSE}
attendance <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/attendance.csv")
standings <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/standings.csv")


```
```{r vista-dataset}
attendance %>% glimpse()
standings %>%  glimpse()

```


## Unión de los datasets

Ya leímos el dataset *attendance* y *standings*:

- attendance: datos de la asistencia/marca los equipos. 

- standings: datos de la clasificación de los equipos con sus respectivas marcas. 

A continuación vamos a unir ambos usando la sentencia left_join y mediante los siguientes campos: c("year", "team_name", "team"))



```{r union_datasets, echo=FALSE, message=FALSE, warning=FALSE}

attendance_joined <- attendance %>%
  left_join(standings,
    by = c("year", "team_name", "team")
  )

attendance_joined
```
## Objetivo
Nuestro objetivo aquí es crear algunos modelos muy simples para la asistencia a la NFL a partir del conjunto de datos #TidyTuesday.


## Análisis exploratorio inicial

```{r boxplot-inicial, echo=FALSE, message=FALSE, warning=FALSE, fig.height=7, fig.width=10, fig.show = "hold", fig.align='center'}
attendance_joined %>%
  filter(!is.na(weekly_attendance)) %>%
  ggplot(aes(fct_reorder(team_name, weekly_attendance),
    weekly_attendance,
    fill = playoffs
  )) +
  geom_boxplot(outlier.alpha = 0.5) +
  coord_flip() +
  labs(
    fill = NULL, x = NULL,
    y = "Asistencia semanal de juegos de la NFL"
  )

# playoffs: eliminatorias, columna que contiene 2 posibles valores: eliminado y no eliminado.
```


Tengamos en cuenta que para los 32 equipos de la NFL, existen años en que lo dieron todo y aún así no llegaron a los playoffs, lo que será bueno para modelar.

¿Cuánto *margin_of_victory*, una medida de los puntos anotados en relación con los puntos permitidos, mide llegar a los playoffs o eliminatorias?

```{r histograma, warning=FALSE, fig.height=7, fig.width=10, fig.show = "hold", fig.align='center'}
attendance_joined %>%
  distinct(team_name, year, margin_of_victory, playoffs) %>%
  ggplot(aes(margin_of_victory, fill = playoffs)) +
  geom_histogram(position = "identity", alpha = 0.7) +
  labs(
    x = "Margien de victoria",
    y = "Númmero de equipos",
    fill = NULL
  )


```
### ¿Hay cambios con la semana de la temporada?

```{r boxplot, warning=FALSE, fig.height=5, fig.width=8, fig.show = "hold", fig.align='center'}
attendance_joined %>%
  mutate(week = factor(week)) %>%
  ggplot(aes(week, weekly_attendance, fill = week)) +
  geom_boxplot(show.legend = FALSE, outlier.alpha = 0.5) +
  labs(
    x = "Semana de la temporada de la NFL",
    y = "Asistencia semanal de juegos de la NFL"
  )
```
## Hemos realizado un breve análisis exploratorio de datos, el cual siempre es una parte importante de la tarea de modelado. El siguiente paso es generar un conjunto de datos para modelar.

Eliminemos las semanas que cada equipo no jugó (es decir, donde la asistencia semanal es NA).
Conservemos únicamente las columnas que queremos usar para el modelado. Por ejemplo, mantendremos *margin_of_victory* y *Strength_of_schedule*, pero no *simple_rating*, que es la suma de esas dos primeras cantidades.


```{r elimino_na, message=FALSE, warning=FALSE}
attendance_df <- attendance_joined %>%
  filter(!is.na(weekly_attendance)) %>%
  select(
    weekly_attendance, team_name, year, week,
    margin_of_victory, strength_of_schedule, playoffs
  )

attendance_df
```
## Modelos simples con tidymodels
¡Ahora es el momento de cargar el metapaquete tidymodels! 💪 El primer paso aquí es dividir nuestros datos en pruebas de entrenamiento y pruebas. Podemos usar *initial_split ()* para crear estos conjuntos de datos, divididos para que cada uno tenga aproximadamente la misma cantidad de ejemplos de equipos que pasaron a los playoffs.


```{r division_datos, message=FALSE, warning=FALSE}
library(tidymodels)

set.seed(1234)
attendance_split <- attendance_df %>%
  initial_split(strata = playoffs)

nfl_train <- training(attendance_split)
nfl_test <- testing(attendance_split)
```
## Ajuste del modelo utilizando lm

```{r regresion_lineal, message=FALSE, warning=FALSE}
lm_spec <- linear_reg() %>%
  set_engine(engine = "lm")

lm_spec
## Linear Regression Model Specification (regression)
##
## Computational engine: lm
lm_fit <- lm_spec %>%
  fit(weekly_attendance ~ .,
    data = nfl_train
  )

lm_fit

```

Ya fiteamos el primer modelo, ahora vamos por el segundo.

```{r random_forest, message=FALSE, warning=FALSE }

rf_spec <- rand_forest(mode = "regression") %>%
  set_engine("ranger")

rf_spec

```

## Ajuste del modelo utilizando random forest

```{r}
library('ranger')
rf_fit <- rf_spec %>%
  fit(weekly_attendance ~ ., data = nfl_train)

rf_fit

```

Observe que hemos ajustado ambos modelos utilizando nfl_train, es decir, los datos de entrenamiento. No hemos tocado los datos de las pruebas durante el entrenamiento.


## Evaluación de los modelos
Cuando sea el momento de evaluar nuestros modelos (para estimar qué tan bien funcionarán nuestros modelos con datos nuevos), analizaremos nfl_test. Podemos predecir () cuál será la asistencia semanal tanto para los datos de entrenamiento como para los datos de prueba utilizando los modelos OLS y de bosque aleatorio. Uno de los objetivos de tidymodels es poder utilizar código como el siguiente de formas predecibles y coherentes para muchos tipos de modelos, y utilizar las herramientas de tidyverse adecuadas para este tipo de tareas.


```{r resultados, message=FALSE, warning=FALSE}
results_train <- lm_fit %>%
  predict(new_data = nfl_train) %>%
  mutate(
    truth = nfl_train$weekly_attendance,
    model = "lm"
  ) %>%
  bind_rows(rf_fit %>%
    predict(new_data = nfl_train) %>%
    mutate(
      truth = nfl_train$weekly_attendance,
      model = "rf"
    ))

results_test <- lm_fit %>%
  predict(new_data = nfl_test) %>%
  mutate(
    truth = nfl_test$weekly_attendance,
    model = "lm"
  ) %>%
  bind_rows(rf_fit %>%
    predict(new_data = nfl_test) %>%
    mutate(
      truth = nfl_test$weekly_attendance,
      model = "rf"
    ))

```

Para este modelo de regresión, veamos el **rmse** de lo que hemos hecho hasta ahora.

```{r resultado_rsme_train, message=FALSE, warning=FALSE}
results_train %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred)

```

```{r resultado_rsme_test, message=FALSE, warning=FALSE}
results_test %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred)

```
## ¿Malas decisiones?
Si miramos los datos de entrenamiento, el modelo de bosque aleatorio funcionó mucho mejor que el modelo lineal; el rmse es mucho menor. Sin embargo, no se puede decir lo mismo de los datos de prueba. 😭 La métrica para el entrenamiento y las pruebas para el modelo lineal es aproximadamente la misma, lo que significa que no hemos sobreajustado. Para el modelo de bosque aleatorio, la rmse es mucho más alta para los datos de prueba que para los datos de entrenamiento. Nuestros datos de entrenamiento no nos dan una buena idea de cómo funcionará nuestro modelo, y este poderoso algoritmo ML se ha sobreajustado a este conjunto de datos.


```{r grafico_resultado_test, echo=TRUE, fig.align='center', fig.height=5, fig.show="hold", fig.width=8, message=FALSE, warning=FALSE}
results_test %>%
  mutate(train = "testing") %>%
  bind_rows(results_train %>%
    mutate(train = "training")) %>%
  ggplot(aes(truth, .pred, color = model)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.5) +
  facet_wrap(~train) +
  labs(
    x = "Valor real",
    y = "Asitencia predicha",
    color = "Tipo de modelo"
  )

```
## Intentemos mejorar el modelo
No tomamos una decisión tan buena en la sección anterior; esperábamos que el modelo de bosque aleatorio evaluado una vez en todo el conjunto de entrenamiento nos ayudara a comprender algo sobre cómo funcionaría con nuevos datos. Esta sería una expectativa razonable para el modelo lineal, pero no para el bosque aleatorio. Afortunadamente, tenemos algunas opciones. Podemos volver a muestrear el conjunto de entrenamiento para producir una estimación de cómo funcionará el modelo. Dividamos nuestro conjunto de entrenamiento nfl_train en pliegues (digamos, 10) y ajustemos 10 versiones de nuestro modelo (cada una entrenada en nueve pliegues y evaluada en un pliegue retenido). Luego, midamos qué tan bien se desempeñan nuestros modelos. La función vfold_cv () crea pliegues para validación cruzada, la función fit_resamples () ajusta modelos a remuestreos como estos (para medir el desempeño), y luego podemos recolectar_metrics () del resultado.



```{r resampleo, echo=TRUE, message=FALSE, warning=FALSE}
set.seed(1234)
nfl_folds <- vfold_cv(nfl_train, strata = playoffs)

rf_res <- fit_resamples(
  weekly_attendance ~ .,
  rf_spec,
  nfl_folds,
  control = control_resamples(save_pred = TRUE)
)

rf_res %>%
  collect_metrics()
```
Recuerde que este sigue siendo el conjunto de datos de entrenamiento. Daríamos este paso en lugar del fragmento anterior con predecir (new_data = nfl_train), y aún compararíamos el rendimiento del modelo en los datos de prueba. Tenga en cuenta que ahora tenemos una estimación realista de los datos de entrenamiento que se acerca a los datos de prueba. Incluso podemos visualizar los resultados de nuestro modelo para los remuestreos.

```{r  grafico_final, echo=TRUE, fig.align='center', fig.height=5, fig.show="hold", fig.width=8, message=FALSE, warning=FALSE}
rf_res %>%
  unnest(.predictions) %>%
  ggplot(aes(weekly_attendance, .pred, color = id)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.5) +
  labs(
    x = "Valor real",
    y = "Asistencia del juego predicha",
    color = NULL
  )
```


## Referencias:
 * [Blog de Julia Silge](https://juliasilge.com/blog/intro-tidymodels/)
 
 * [Sitio de Tidymodels](https://www.tidymodels.org/)

